# CPU與指令

## CPU簡介

<figure><img src="../.gitbook/assets/image (1).png" alt=""><figcaption><p>CPU 的操作簡介。右手邊這個是CPU的指令，他的意思是，R1暫存器儲存100這個數值，R2暫存器讀取記憶體中0x100這個記憶體位置的數值(也就是10)，然後R3暫存器會是R1,R2這兩個數值加起來，最後再把R3暫存器的數值存到記憶體中0x110 的位置，理論上數值會是110。</p></figcaption></figure>

超級簡化的來說，一台電腦包含一個處理器(central processing unit, CPU)連著一些記憶體(memory)，上面這張圖解釋了一般CPU的操作

1. 從記憶體讀取(Load)數值，把它放到暫存器(register)和從暫存器把數值儲存(save)到記憶體
2. CPU只會操作在暫存器的資料。例如，在兩個暫存器之中做加減乘除、執行位元操作(bitwise and, or,之類的操作)、或是其他數學計算(平方根, sin, cos, tan 之類的)

因此，在這張圖中，描述我們CPU簡單的存取記憶體中的數字，加100之後再儲存在記憶體之中。



## 分支(Branching)

除了存取資料以外，CPU還有一種重要的操作就是**Branching**，CPU內部會保存「下一個指令的位置」，這個資訊存放在_`instruction pointer`_裡面。通常，指令指標會遞增指向下一個要執行的CPU的指令，分支指令通常會檢查特定的暫存器是否為零或是有特殊標記，如果有的話，就會修改指令指標到一個不同的記憶體位置，因此，下一個要執行的指令就會跳到程式的其他位置，這個就是一般迴圈跟if else的在　CPU指令執行的樣子。

舉個例子，如果我們寫 if(x==0)，這樣子的程式，我們需要兩個暫存器，R1放x的數值，R2放0，如果這兩個暫存器比較的結果是零(用 R1 or R2 == 0? 或 R1 | R2 == 0 ?)，就代表x 這個數值是0，這個條件成立，所以執行接下來的程式碼，如果沒有成立的話，就把指針只到另外一個地方(else的地方)



## CPU時派(Cycles)

我們都知道電腦的速度用 Mhz 跟 GHz 表示(每秒百萬次，或每秒十億次)，我們稱這個速度叫做時脈(clock speed)，因為他就是電腦內部時鐘脈衝的速度。

處利器內部使用脈衝來保持同步，每一次脈衝，就可以開始一個新的操作。可以把他想像成，每敲一次鼓，船上的人就划一次槳，的這種感覺，他們會保持同步。

## 提取( Fetch), 解碼(Decode),執行( Execute),(儲存) Store

執行一條指令包含以下這些時間：拿取＋解碼＋執行＋儲存資料。

也就是說，在CPU上面要執行 add 的指令，必須

1. 提取：將指令從記憶體輸入到處理器中
2. 解碼：CPU 解碼這個指令的意思(在這個範例之中，CPU 會知道要 `add`)
3. 執行：從暫存器拿取數值，把數字加在一起
4. 儲存：把結果儲存到另外一個暫存器，這個步驟叫做 _**retiring**_** ** 指令

### **看看 CPU的內部構造**

在CPU裡面有很多不同的部分在執行剛剛說到的每一個步驟，通常這些步驟都可以被獨立的執行。這就好像是一條工廠生產線一樣，有很多站點。每一個步驟都有一個特定的任務要執行，當這個任務執行完畢的時候，就會把結果傳遞給下一個站點，然後接收上一站點的新的工作。

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption><p>這張圖是CPU的內部構造，這張圖簡介了現代處理器裡面一些主要的原件，裡面有解碼(decode)，算術運算(ALC)、浮點數運算(FPU)、快取記憶體(cache)等，CPU可以直接存取記憶體(RAM)，並且接受指令的輸入。</p></figcaption></figure>



在這張圖之中，我們可以看到指令(instructions)進入CPU之後，會先被解碼。CPU裡面有兩種暫存器。一種是給整數運算用的，另外一個是給浮點數運算用的。浮點數是一種以二進位的形式來表達小數位數的方法(可以看ieee的754 ，跟我想的都不一樣XD)，浮點數的運算在每種不同的CPU中處理的方式都有所不同。MMX(multimedia extension)、 _SSE_ (Streaming Single Instruction Multiple Data)、_Altivec_ 暫存器這些都是用來處理浮點數的暫存器。

所謂的 _register file_ 是CPU內部暫存器的統稱。下面會介紹CPU各個部份的工作內容。

剛剛有說到，處理就要不就把數值讀取到暫存器中，要不就把暫存器的數值存到記憶體中、要不就是對暫存器的數值進行一些運算操作，所以

**算數邏輯單元(**_**Arithmetic Logic Unit,**_** ALU)** 就是CPU的的核心，他讀取暫存器的數值，執行各種CPU運算操作。現代的處理器有很多個ALU，每個都可以獨立工作。例如 intel Pentium  系列的處理器就同時存在快的ALU跟慢的ALU，快的比較小(可以塞更多顆、執行簡單常見任務)，慢得比較大顆，但是可以執行其他所有的CPU操作。

**位置生成單元(**_**Address Generation Unit,**_** AGU)**，處理快取(cache)跟主要記憶體的溝通。可以讓CPU讀取到正確的記憶體位置的那個數值，並且把計算之後的結果返回指定的記憶體位置。

浮點數暫存器的概念大概都差不多，但在不同的製造商之中有不同的專業術語跟結構

### **Pipelining**

就跟我們剛剛說的一樣，當 ALU 將站存器的數值們加起來，跟 AGU 將算出來的數值存回記憶體，這兩件事情完全獨立，所以 CPU 沒有理由不能同時處理這兩件事情。更何況，我們還有很多個獨立的 ALU ，每一個 ALU 都可以處理不同的指令。當然， CP依可以執行浮點數運算的時候同時執行整數運算。這種互相獨立的任務處理我們叫做 _pipelining_ 。可以這樣處理的CPU我們叫他 _superscalar architecture_ 所有的現代處理器都是這種架構。

我們可以把 pipeline 想像成水管裡面有很多彈珠，彈珠就是 CPU指令。理想的情況下，你會把你的彈珠塞到其中一端，一個接著一個塞，照著時脈塞進去。一旦整個水管滿了，你推入一個新的彈珠(指令)就會把所有的彈珠(指令)往前推一格，然後會有一個彈珠掉出來(答案掉出來)。

但是分支指令會破壞這個運作模式，因為他們可能會，也可能不會跳著執行指令。如果你是一條水管，現代 CPU 的作法就是會先猜猜看會往哪個分支走，所以你就會知道接下來要執行什麼指令。如果你猜對了，那就會運行的很順暢，相反的，如果你猜錯了，你就會浪費很多時間，把水管理面的指令通通清楚，然後重新再來一次。

這個過程通常被稱為 _`pipeline flush`_ ，也就是描述從水管中清空你所有的彈珠指令的行為。

#### **分支預測 Branch Prediction**

pipeline flush, predict taken, predict not taken, branch delay slots

### **重新排列 Reordering**

如果把 CPU 當作是水管，他可以自由的重新排列裡面的彈珠，只要他最後彈出來的順序跟你放的順序相同就可以。我們稱這種順序叫做 _program order_  因為這個是指令在電腦程式中的順序。&#x20;

```
// instruction stream 
1: r3 = r1 * r2
2: r4 = r2 + r3
3: r7 = r5 * r6
4: r8 = r1 + r7
```

考慮一組指令，長的跟上面一樣，指令2要等指令1 完成後才可以開始。這表示這個pipeline需要等待( stall) 因為他需要上一個指令的結果。此外，指令3跟指令4也是類似的關係，也就是指令4要等待r7 的結果，才可以開始運算。但是，指令２跟指令3 完全不相關，以就是他們在完全不相關的暫存器上面運算。所以當我們交換指令2跟3，並不會影響結果，這樣會是一個更有效率的安排，因為執行完指令1之後可以馬上執行指令3，不需要等待指令1執行完之後在執行指令3 。

但是，當我們在些非常底層的程式碼(i.e. 嵌入式或是driver)的時候，為了安全性，會要求指令執行的順序，這種要求我們稱為　_memory semantics 。_如果你要 a_cquire_ semantics代表你必須保證先前所有指令的結果已經完成。如果你要 _release_ semantics 代表之後所有的指令應該都要看得到你現在的指令執行結果。另外一種更嚴格的叫做 _memory barrier_ 或是 _memory fence，_這個代表指令的結果必須先儲存到記憶體之中，才可以執行其他操作。

在某些CPU架構中，處理器會保證幫你達成這些語意(semantics)，但也有些架構需要你顯示的指定語意。大部分程式設計師不太需要擔心他們，但是會看到這些術語。

### CISC v RISC

電腦有兩種架構，一種是複雜指令集(_Complex Instruction Set Computer,_ CISC) ，一種是精簡指令集(_Reduced Instruction Set Computer,_ RISC)

我們剛剛在第一個範例之中，我們就顯示的把數值加到暫存器，然後執行一個加法，然後存到另外一個暫存器，並把結果儲存到記憶體之中。這個就是RISC的運算執行方法的一個例子。也就是，只對暫存器的數值執行操作，並且顯式地從記憶體存取數值。

CISC 的方法則是一個單一的指令，就可以從記憶體讀取資料，在運算單元執行加法，最後把執行的結果除存回記憶體。這就表示一個指令可能會是很多個 CPU 週期。無論如何，這兩種方法都實現了一樣的目標。

所有現代處理器都被認為是 RISC 架構。因為以下這些原因

* RISC 使得撰寫組合語言變得困難，但大部分的程式工程師都是用高階寫程式，所以這個困難產生組合語言的困難工作就是編譯器的責任了，所以這個缺點瑕不掩瑜
* 因為 RISC 處理企的指令比較簡單，所以會CPU 晶片裡面可以放更多的暫存器。依照目前的記憶體架構，暫存器是最快的記憶體類型，而且所有的指令最終都必須在暫存器中執行，所以在其他條件都一樣的情況下，更多的暫存器可以提昇效能。
* 因為所有的指令都同時執行，所以可以做pipeline。我們知道這個操作需要連續不斷的把指令輸入處理器，如果有些指令要花很久的時間，有些指令只花一點時間，那這個pipeline就會變得很複雜，就很難變得很有效率。

### **EPIC**

intel 的 Itanium 處理器，也就是這本書範例中使用的處理器，是一個改善的處理器架構，稱為Explicitly Parallel Instruction Computing。

我幫剛剛有提到 superscaler 處理器有很多組 pipelines 同時執行不同的指令，就是顯然的想要增加單一個時間可以處理的指令數量，並且盡量的使用處理器的每一個部份。

傳統處理器是用硬體解碼組織指令輸入，指令會依序輸入處理器，處理器必須要預讀一些指令，然後嘗試去做organise 接下來的指令。

EPICE 背後的理論就是，在更高層的地方有更多資訊可以做出比處理器更好的決定。跟處理器一樣分析組合語言的順序會流失程式工程師在原來程式碼想表達的想法。就好像直接讀莎士比亞的原著，跟簡化的版本，兩者都給你一樣的結果，但原始的版本有更多的細節，場景，讓你可以理解各個角色的情緒。

所以，指令的邏輯順序排列就從處理器的工作變成編譯器的工作，所以編譯器的作者必須要更聰明的幫處理器找到最佳的指令順序。處理器就可以大大的被簡化，因為很多工作都被轉移給編譯器了。



